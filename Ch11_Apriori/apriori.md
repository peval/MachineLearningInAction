第11章 使用Apriori算法进行关联分析 
==========================================

从大规模数据集中寻找物品间的隐含关系被称作**关联分析（association analysis）**或者**关联规则学习（association rule learning）**。这里的主要问题在于，寻找物品的不同组合是一项十分耗时的任务，所需的计算代价很高，蛮力搜索方法并不能解决这个问题，所以需要用更智能的方法在合理的时间范围内找到频繁项集。

关联分析可以用于回答"哪些商品经常被同时购买？"之类的问题。书中举了一些关联分析的例子:

- 通过查看哪些商品经常在一起购买，可以帮助商店了解用户的购买行为。这种从数据海洋中抽取的知识可以用于商品定价、市场促销、存活管理等环节。

- 在美国国会投票记录中发现关联规则。在一个国会投票记录的数据集中发现议案投票的相关性，（原文：这里只是出于娱乐的目的，不过也可以……）使用分析结果来为政治竞选活动服务，或者预测选举官员会如何投票。

- 发现毒蘑菇的相似特征。这里只对包含某个特定元素（有毒性）的项集感兴趣，从中寻找毒蘑菇中的一些公共特征，利用这些特征来避免吃到那些有毒蘑菇。

- 在Twitter源中发现一些共现词。对于给定搜索词，发现推文中频繁出现的单词集合。

- 从新闻网站点击流中挖掘新闻流行趋势，挖掘哪些新闻广泛被用户浏览到。

- 搜索引擎推荐，在用户输入查询词时推荐同相关的查询词项。

# 1 关联分析

关联分析是在大规模数据集中寻找有趣关系的任务。这些关系可以有两种形式：

- 频繁项集

- 关联规则

**频繁项集（frequent item sets)** 是经常出现在一块儿的物品的集合，**关联规则（association rules)** 暗示两种物品之间可能存在很强的关系。

下面用一个例子来说明这两种概念：图1给出了某个杂货店的交易清单。

交易号码|    商品
------- | ------------
0       |  豆奶，莴苣
1       |  莴苣，尿布，葡萄酒，甜菜
2       |  豆奶，尿布，葡萄酒，橙汁
3       |  莴苣，豆奶，尿布，葡萄酒
4       |  莴苣，豆奶，尿布，橙汁

    图1 某杂货店交易清单

**频繁项集是指那些经常出现在一起的商品集合**，图中的集合{葡萄酒,尿布,豆奶}就是频繁项集的一个例子。从这个数据集中也可以找到诸如尿布->葡萄酒的关联规则，即如果有人买了尿布，那么他很可能也会买葡萄酒。

我们用**支持度**和**可信度**来度量这些有趣的关系。一个**项集的支持度（support）**被定义数据集中包含该项集的记录所占的比例。如上图中，{豆奶}的支持度为4/5，{豆奶,尿布}的支持度为3/5。支持度是针对项集来说的，因此可以定义一个最小支持度，而只保留满足最小值尺度的项集。

**可信度或置信度（confidence）**是针对**关联规则**来定义的。规则{尿布}➞{啤酒}的可信度被定义为"支持度({尿布,啤酒})/支持度({尿布})"，由于{尿布,啤酒}的支持度为3/5，尿布的支持度为4/5，所以"尿布➞啤酒"的可信度为3/4。这意味着对于包含"尿布"的所有记录，我们的规则对其中75%的记录都适用。 **规则{尿布}➞{啤酒} 可理解为条件概率，已知在购买尿布的情况下，还购买啤酒的概率**。

# 2 Apriori原理
假设我们有一家经营着4种商品（商品0，商品1，商品2和商品3）的杂货店，2图显示了所有商品之间所有的可能组合：

![杂货店所有商品之间所有的可能组合](杂货店所有商品之间所有的可能组合.png)

图2 集合{0,1,2,3,4}中所有可能的项集组合

对于包含N中物品的数据集共有$2^N - 1$种项集组合，重复上述计算过程是不现实的。

研究人员发现一种所谓的**Apriori原理，可以帮助我们减少计算量**。**Apriori原理是说如果某个项集是频繁的，那么它的所有子集也是频繁的**。更常用的是它的逆否命题，即**如果一个项集是非频繁的，那么它的所有超集也是非频繁的**。

在图3中，已知阴影项集{2,3}是非频繁的。利用这个知识，我们就知道项集{0,2,3}，{1,2,3}以及{0,1,2,3}也是非频繁的。也就是说，一旦计算出了{2,3}的支持度，知道它是非频繁的后，就可以紧接着排除{0,2,3}、{1,2,3}和{0,1,2,3}。

![Apriori原理](Apriori原理.png)
图3 图中给出了所有可能的项集，其中非频繁项集用灰色表示。




