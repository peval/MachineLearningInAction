第8章 预测数值型数据：回归
=========================
回归与分类的**不同**：在于其目标变量是连续数值型，而分类的目标变量是标称型数据。

# 1 用母性回归找到最佳拟合直线

**线性回归**

**优点**：结果易于理解，计算上不复杂。

**缺点**：对非线性的数据拟合不好。

**适用数据范围**：数值型和标称型数据。

**回归目的**: 预测数值型的目标值，最直接的办法是依据输入样本数据输出一个目标值的计算公式。

假如你要预测姐姐男友汽车的功率大小，可能会这么计算

    HorsePower = 0.0015*annualSalary(年薪) - 0.99*hoursListeningToPublicRadio(听广播时间)

这就是所谓的**回归方程(regression equation)**,其中0.0015与-0.99称作**回归系数(regression weights)**,求这些回归系数的过程就是**回归**。一旦有了回归系数，再给定输入时，直接用回归系统乘以输入值，再将结果全部加起来，就得到了**预测值**。

回归分为线性回归与非线性回归。一般我们使用线性回归，即可以将输入项分别乘以一些常量，再将结果加起来得到输出。非线性回归模型则认为输出可能是输入的乘积.

    HorsePower = 0.0015*annualSalary(年薪)/hoursListeningToPublicRadio







