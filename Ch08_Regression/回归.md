第8章 预测数值型数据：回归
=========================
回归与分类的**不同**：在于其目标变量是连续数值型，而分类的目标变量是标称型数据。

# 1 用线性回归找到最佳拟合直线

**线性回归**

**优点**：结果易于理解，计算上不复杂。

**缺点**：对非线性的数据拟合不好。

**适用数据范围**：数值型和标称型数据。

**回归目的**: 预测数值型的目标值，最直接的办法是依据输入样本数据输出一个目标值的计算公式。

假如你要预测姐姐男友汽车的功率大小，可能会这么计算

    HorsePower = 0.0015*annualSalary(年薪) - 0.99*hoursListeningToPublicRadio(听广播时间)

这就是所谓的**回归方程(regression equation)**,其中0.0015与-0.99称作**回归系数(regression weights)**,求这些回归系数的过程就是**回归**。一旦有了回归系数，再给定输入时，直接用回归系统乘以输入值，再将结果全部加起来，就得到了**预测值**。

回归分为线性回归与非线性回归。一般我们使用线性回归，即可以将输入项分别乘以一些常量，再将结果加起来得到输出。非线性回归模型则认为输出可能是输入的乘积.

    HorsePower = 0.0015*annualSalary(年薪)/hoursListeningToPublicRadio

回归的一般方法

    1. 收集数据： 采用任意方法收集数据
    
    2. 准备数据：回归需要数值型数据，标称型数据将被转成二值型数据。

    3. 分析数据：给出数据的可视化二维图将有助于对数据做出理解和分析，在采用缩减法求得新回归系数之后，可以将新拟合线绘在图上作为对比。

    4. 训练算法：找到回归系数。

    5. 测试算法：使用$R^2$或者预测值和数据的拟合度，来分析模型的效果。

    6. 使用算法：使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测连续型数据而不仅仅是离散的类别标签。


怎么求回归方程？假定输入数据存放在矩阵$X$中，而回归系数存放在向量$w$中。那么对于给定的数据$X_1$,预测结果将会通过$Y_1 = X^{T}_{1}w$给出。





